{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# directory = 'data/BIGFOIL_DAT'\n",
    "# winglist_name = []\n",
    "# winglist_size = []\n",
    "\n",
    "# # iterate over files in that directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     f = os.path.join(directory, filename)\n",
    "#     # checking if it is a file\n",
    "#     if os.path.isfile(f):\n",
    "#         #print(f)\n",
    "#         with open(f, 'r') as f:\n",
    "#             content = f.read()\n",
    "#             #print(filename, len(content))\n",
    "#             winglist_name.append(filename)\n",
    "#             winglist_size.append(len(content))\n",
    "\n",
    "# df_index = pd.DataFrame({'name':winglist_name, 'size':winglist_size})\n",
    "# df_index.to_csv('data/dat_files_index.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV and check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 8353 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8353, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a18.DAT</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a18sm.DAT</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A6014-S.DAT</td>\n",
       "      <td>6116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6016-S.DAT</td>\n",
       "      <td>5914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A6018-S.DAT</td>\n",
       "      <td>5889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Size\n",
       "0      a18.DAT   945\n",
       "1    a18sm.DAT  1795\n",
       "2  A6014-S.DAT  6116\n",
       "3  A6016-S.DAT  5914\n",
       "4  A6018-S.DAT  5889"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat = pd.read_csv('data/dat_files_index.csv', usecols=('name', 'size'))\n",
    "df_dat.rename(columns={'name':'Name', 'size':'Size'}, inplace=True)\n",
    "print(df_dat.shape)\n",
    "df_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons dans la bigtable : 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Checking if the dataset contains duplicates\n",
    "doublon_datfile = df_dat['Name'].value_counts().index[df_dat['Name'].value_counts().values > 1]\n",
    "print(f'Nombre de doublons dans la bigtable : {len(doublon_datfile)}')\n",
    "print([i for i in doublon_datfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6324, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63A108 MOD C</td>\n",
       "      <td>NASA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A18</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A18 (SMOOTHED)</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6014-S</td>\n",
       "      <td>Ayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A6016-S</td>\n",
       "      <td>Ayers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name         Family\n",
       "0    63A108 MOD C           NASA\n",
       "1             A18  Uncategorized\n",
       "2  A18 (SMOOTHED)  Uncategorized\n",
       "3         A6014-S          Ayers\n",
       "4         A6016-S          Ayers"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigtable = pd.read_csv('data/ailes_avion.csv', usecols=('Name', 'Family'))\n",
    "print(df_bigtable.shape)\n",
    "df_bigtable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons dans la bigtable : 2\n",
      "['FX 66-17AII-182', 'BOEING 737 MIDSPAN']\n"
     ]
    }
   ],
   "source": [
    "# Checking if the dataset contains duplicates\n",
    "doublon_bigtable = df_bigtable['Name'].value_counts().index[df_bigtable['Name'].value_counts().values > 1]\n",
    "print(f'Nombre de doublons dans la bigtable : {len(doublon_bigtable)}')\n",
    "print([i for i in doublon_bigtable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Basic Regex and exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column Name_modified with all names in lowercase and without the .DAT ending \n",
    "df_dat['Name_modified'] =  df_dat['Name'].apply(lambda x : (re.split(\".DAT$\", str(x)))[0])\n",
    "df_dat['Name_modified'] = df_dat['Name_modified'].apply(lambda x : str(x).lower())\n",
    "# Create a column Name_modified with all names in lowercase\n",
    "df_bigtable['Name_modified'] = df_bigtable['Name'].apply(lambda x : str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual affectation of the duplicates after verification\n",
    "df_bigtable.loc[596, ['Name_modified']] = 'fx6617ai'\n",
    "df_bigtable.loc[597, ['Name_modified']] = 'fx6617a2'\n",
    "df_bigtable.loc[154, ['Name_modified']] = 'b737c'\n",
    "df_bigtable.loc[155, ['Name_modified']] = 'b737b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family exceptions beginning by 'g'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'gu25-5(11)8', 'Name_modified'] = 'gu255118'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'gs-1', 'Name_modified'] = 'gs1'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'griffith 30% suction airfoil', 'Name_modified'] = 'griffith30symsuction'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'goe 167 (v.karman prop.2)', 'Name_modified'] = 'goe167'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'glenn martin 2', 'Name_modified'] = 'glennmartin2'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'glenn martin 3', 'Name_modified'] = 'glennmartin3'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'glenn martin 4', 'Name_modified'] = 'glennmartin4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler 377mod', 'Name_modified'] = 'e377m'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler e193gu-k24', 'Name_modified'] = 'e193gu-k24'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler ste 87(-3)-914', 'Name_modified'] = 'ste87391'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler ste 871-514', 'Name_modified'] = 'ste87151'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler stf 863-615', 'Name_modified'] = 'stf86361'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'aquila 9.3% smoothed', 'Name_modified'] = 'aquilasm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'bergey bw-3 (smoothed)', 'Name_modified'] = 'bw3'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'clark-y 11.7% smoothed', 'Name_modified'] = 'clarkysm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'cody robertson cr 001 r/c hand-launch low reynolds number airfoil (smoothed)', 'Name_modified'] = 'cr001sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'dale house dh4009 (smoothed) used on the storm r/c aerobatic aircraft', 'Name_modified'] = 'dh4009sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'fx 60-100 10.0% smoothed', 'Name_modified'] = 'fx60100sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'fx 63-137 13.7% smoothed', 'Name_modified'] = 'fx63137sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'fx 74-cl5-140 mod (smoothed)', 'Name_modified'] = 'fx74modsm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'mb253515 15.0% smoothed', 'Name_modified'] = 'mb253515sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'r140 12.04% (smoothed)', 'Name_modified'] = 'r140sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'spica 11.73% smoothed', 'Name_modified'] = 'spicasm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'usnps4 (smoothed)', 'Name_modified'] = 'usnps4'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'wb-135/35 13.5% smoothed', 'Name_modified'] = 'wb13535sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .08 span', 'Name_modified'] = 'b707a'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .19 span', 'Name_modified'] = 'b707b'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .40 span', 'Name_modified'] = 'b707c'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .54 span', 'Name_modified'] = 'b707d'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .99 span', 'Name_modified'] = 'b707e'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 103', 'Name_modified'] = 'boe103'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 106', 'Name_modified'] = 'boe106'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 737 root', 'Name_modified'] = 'b737a'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 737 outboard', 'Name_modified'] = 'b737d'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'kc-135 bl124.32', 'Name_modified'] = 'kc135b'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'kc-135 bl200.76', 'Name_modified'] = 'kc135c'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'kc-135 bl351.6', 'Name_modified'] = 'kc135d'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'kc-135 bl52.44', 'Name_modified'] = 'kc135a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'naca m6 (65%)', 'Name_modified'] = 'm6_65'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'naca m6 (85%)', 'Name_modified'] = 'm6_85'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge both dataset, return merge\n",
    "def merge_df(df_bigtable, df_dat, on_column):\n",
    "    df_merge = pd.merge(df_bigtable, df_dat, on=on_column, how='left', suffixes=('_big', '_dat'))\n",
    "    nb_mismatch = df_merge[df_merge['Name_dat'].isna()].shape[0]\n",
    "    nb_match = df_merge.shape[0] - nb_mismatch\n",
    "    print(f'Le dataset contient {df_merge.shape[0]} valeurs dont {nb_match} correspondent aux fichiers dat.')\n",
    "    print(f'Il reste {nb_mismatch} valeurs à matcher.')\n",
    "    df_merge.head()\n",
    "    return df_merge\n",
    "\n",
    "def get_family_done(df_merge, nb):\n",
    "    family = df_merge.groupby(['Family']).count()\n",
    "    mask_family = (family['Name_big'] == family['Name_dat'])\n",
    "    res = family[mask_family].Name_big.sort_values(ascending=False).head(nb)\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "# Function to evaluate the missing values per family\n",
    "def groupna_family(df_merge, nb):\n",
    "    family = df_merge.groupby(['Family']).count()\n",
    "    mask_family = (family['Name_big'] != family['Name_dat'])\n",
    "    family_na = family[mask_family].copy()\n",
    "    family_na['nb_na'] = family_na['Name_big'] - family_na['Size']\n",
    "    # We are interested by the 5 families with the most of na\n",
    "    print(family_na['nb_na'].sort_values(ascending=False).head(nb))\n",
    "\n",
    "# Function to iinitialize df_big et df_dat\n",
    "# We want to look through the wings left in each dataframe in order to avoid corrupting good matchs\n",
    "\n",
    "def initiate_df_left(df_bigtable, df_dat, df_merge):\n",
    "    # Create df_dat_left and df_big_left\n",
    "    df_dat_left = pd.merge(df_bigtable, df_dat, on='Name_modified', how='right', suffixes=('_big', '_dat'))\n",
    "    df_dat_left = df_dat_left[df_dat_left['Name_big'].isna()].copy()\n",
    "    print(f\"Unmatched values left in the dat folder : {df_dat_left.shape}\")\n",
    "    df_big_left = df_merge[df_merge['Name_dat'].isna()].copy()\n",
    "    print(f\"Unmatched values left in big table : {df_big_left.shape}\")\n",
    "\n",
    "    # Create a new column for each df containing the first letter of each wing\n",
    "    df_dat_left['First letter'] = [x[0] for x in df_dat_left['Name_modified'].values]\n",
    "    df_big_left['First letter'] = [x[0] for x in df_big_left['Name_modified'].values]\n",
    "\n",
    "    # Create a new column for each df with z copy of the modified name to further work on\n",
    "    df_dat_left['Name_modified_by_family'] = df_dat_left['Name_modified'].copy()\n",
    "    df_big_left['Name_modified_by_family'] = df_big_left['Name_modified'].copy()\n",
    "\n",
    "    # Create a new column for each df with z copy of the modified name to further work on\n",
    "    df_dat_left['Name_modified_by_pattern'] = df_dat_left['Name_modified'].copy()\n",
    "    df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified'].copy()\n",
    "\n",
    "\n",
    "    # df_dat_left ----> ['Name_big', 'Family', 'Name_modified', 'Name_dat', 'Size', 'First letter', 'Name_modified_by_family']\n",
    "    # Name_big and Family are NaN\n",
    "    df_dat_left.drop(columns=['Name_big', 'Family'], inplace=True)\n",
    "    # df_big_left ----> ['Name_big', 'Family', 'Name_modified', 'Name_dat', 'Size', 'First letter', 'Name_modified_by_family']\n",
    "    # Name_dat and Size are NaN\n",
    "    df_big_left.drop(columns=['Name_dat', 'Size'], inplace=True)\n",
    "\n",
    "    return df_dat_left, df_big_left\n",
    "\n",
    "# Function to create filter by letter\n",
    "def get_letter_group(df_dat_left, df_big_left, letter):\n",
    "    big_letter = df_big_left[df_big_left['First letter'] == letter]\n",
    "    dat_letter = df_dat_left[df_dat_left['First letter'] == letter]\n",
    "    print(f'Big table number of wings left beginning by {letter} : {big_letter.shape}')\n",
    "    print(f'Dat folder number of wings left beginning by {letter} : {dat_letter.shape}')\n",
    "    print(f'Difference : {big_letter.shape[0] - dat_letter.shape[0]}')\n",
    "    return big_letter, dat_letter\n",
    "\n",
    "# Function to pass through pattern\n",
    "def try_pattern_family(big_letter, family, pattern_list):\n",
    "    big_letter = big_letter.copy()\n",
    "    for pattern in pattern_list:\n",
    "        # Apply pattern\n",
    "        big_letter.loc[big_letter['Family'] == family, 'Name_modified_by_family'] = big_letter.loc[big_letter['Family'] == family, 'Name_modified_by_family'].apply(pattern)\n",
    "    return big_letter\n",
    "\n",
    "# Function to incorporate the new name found (Name_modified_by_family) into the dataset with the bigtable wings left to match\n",
    "def incorporate_family_pattern(df_big_left, big_letter):\n",
    "    df_big_left = pd.merge(df_big_left, big_letter[['Name_big', 'Name_modified_by_family']], on='Name_big', how='left', suffixes=('_left', '_big'))\n",
    "    df_big_left['Name_modified_by_family_big'] = df_big_left['Name_modified_by_family_big'].fillna(df_big_left['Name_modified_by_family_left'])\n",
    "    df_big_left.drop([\"Name_modified_by_family_left\"], inplace=True, axis=1)\n",
    "    df_big_left.rename(columns={'Name_modified_by_family_big':'Name_modified_by_family'}, inplace=True)\n",
    "    print(df_big_left.columns)\n",
    "    return df_big_left\n",
    "\n",
    "def set_df_left(df_dat_left, df_merge, on_column):\n",
    "    # Create df_dat_left and df_big_left\n",
    "    df_dat_left = pd.merge(df_merge, df_dat_left, on=on_column, how='right', suffixes=('_big', '_dat'))\n",
    "    df_dat_left = df_dat_left[df_dat_left['Name_big'].isna()]\n",
    "    df_dat_left.dropna(axis=1, how='all', inplace=True)\n",
    "    df_dat_left = df_dat_left.set_axis([re.sub('_dat', \"\", str(col)) for col in df_dat_left.columns], axis=1)\n",
    "    df_dat_left.rename(columns={'Name':'Name_dat'}, inplace=True)\n",
    "    print(f\"Unmatched values left in the dat folder : {df_dat_left.shape}\")\n",
    "    df_big_left = df_merge[df_merge['Name_dat'].isna()].copy()\n",
    "    df_big_left.dropna(axis=1, how='all', inplace=True)\n",
    "    df_big_left = df_big_left.set_axis([re.sub('_big', \"\", str(col)) for col in df_big_left.columns], axis=1)\n",
    "    df_big_left.rename(columns={'Name':'Name_big'}, inplace=True)\n",
    "    print(f\"Unmatched values left in big table : {df_big_left.shape}\")\n",
    "    return df_dat_left, df_big_left\n",
    "\n",
    "def try_pattern(df_big_left, df_dat_left, pattern_list):\n",
    "    df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified'].copy()\n",
    "    df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified'].copy()\n",
    "\n",
    "    for pattern in pattern_list:\n",
    "        df_big_left['Name_modified_by_pattern'] = df_big_left.loc[:, 'Name_modified_by_pattern'].apply(pattern)\n",
    "        df_dat_left['Name_modified_by_pattern'] = df_dat_left.loc[:, 'Name_modified_by_pattern'].apply(pattern)\n",
    "\n",
    "    return df_dat_left, df_big_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 6324 valeurs dont 4949 correspondent aux fichiers dat.\n",
      "Il reste 1375 valeurs à matcher.\n",
      "Famille complètes : \n",
      "Family\n",
      "NACA 65-series       608\n",
      "NACA 66-series       604\n",
      "NACA 67-series       548\n",
      "NACA 5-digit         401\n",
      "Habbe                137\n",
      "Horten               133\n",
      "Joukowsky            132\n",
      "Riblett 30-series    114\n",
      "Riblett 40-series    110\n",
      "Riblett 37-series    110\n",
      "Name: Name_big, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_bigtable, df_dat, 'Name_modified')\n",
    "print('Famille complètes : ')\n",
    "done_list = get_family_done(df_merge,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP only after all matching is done \n",
    "df_dat.drop(df_dat[df_dat['Name_modified'].str.contains('horten')].index, inplace=True)\n",
    "df_dat.drop(df_dat[df_dat['Name_modified'].str.contains('joukowsky')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Create dataframes with wings left to match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (2366, 5)\n",
      "Unmatched values left in big table : (1375, 5)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = initiate_df_left(df_bigtable, df_dat, df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Regex to match the family Yost,Eiffel,Eppeler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Gottingen        381\n",
      "Eppler           196\n",
      "Uncategorized    138\n",
      "Wortmann         107\n",
      "NASA              54\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big table number of wings left beginning by e : (216, 6)\n",
      "Dat folder number of wings left beginning by e : (217, 6)\n",
      "Difference : -1\n"
     ]
    }
   ],
   "source": [
    "big_e, dat_e = get_letter_group(df_dat_left, df_big_left, 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yost = [lambda x : (re.sub(\"\\s\", \"\", str(x))), \n",
    "        lambda x : (re.sub(\"\\.\", \"\", str(x))), \n",
    "        lambda x : (re.sub(\"/\", \"\", str(x)))]\n",
    "\n",
    "eiffel = [lambda x : (re.sub('\\(.*?\\)', \"\", str(x))), \n",
    "          lambda x : (re.sub(\"\\s\", \"\", str(x))), \n",
    "          lambda x : (re.split(\"-\", str(x)))[0]]\n",
    "\n",
    "eppler = [lambda x : (re.sub(\"eppler\", \"e\", str(x))), \n",
    "          lambda x : (re.sub(\"\\s\", \"\", str(x)))]\n",
    "\n",
    "big_e = try_pattern_family(big_e, 'Yost', yost)\n",
    "big_e = try_pattern_family(big_e, 'Eiffel', eiffel)\n",
    "big_e = try_pattern_family(big_e, 'Eppler', eppler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name_big', 'Family', 'Name_modified', 'First letter',\n",
      "       'Name_modified_by_pattern', 'Name_modified_by_family'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Function to incorporate the new name found (Name_modified_by_family) into the dataset with the bigtable wings left to match\n",
    "df_big_left = incorporate_family_pattern(df_big_left, big_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 1375 valeurs dont 199 correspondent aux fichiers dat.\n",
      "Il reste 1176 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "# we already did a merge so maybe just add an argument precising the on merge column\n",
    "# By merging using 'left', we obtain 4905 correspondances\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name_big', 'Family', 'Name_modified', 'First letter',\n",
      "       'Name_modified_by_pattern', 'Name_modified_by_family'],\n",
      "      dtype='object')\n",
      "Le dataset contient 1375 valeurs dont 213 correspondent aux fichiers dat.\n",
      "Il reste 1162 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "# eppler_res = df_merge[df_merge['Family'] == 'Eppler']\n",
    "# eppler_res[eppler_res['Name_modified_dat'].isna()].Name_modified_big\n",
    "\n",
    "eppler = [lambda x : (re.sub(\"eppler\", \"e\", str(x))),\n",
    "          lambda x : (re.sub(\"ee\", \"e\", str(x))),\n",
    "          lambda x : (re.sub(\"hydrofoil\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"strut\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"-\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"\\)\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"\\s\", \"\", str(x)))]\n",
    "\n",
    "big_e = try_pattern_family(big_e, 'Eppler', eppler)\n",
    "\n",
    "# Function to incorporate the new name found (Name_modified_by_family) into the dataset with the bigtable wings left to match\n",
    "df_big_left = incorporate_family_pattern(df_big_left, big_e)\n",
    "\n",
    "# we already did a merge so maybe just add an argument precising the on merge column\n",
    "# By merging using 'left', we obtain 4905 correspondances\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Regex to match the family Gottingen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (2153, 6)\n",
      "Unmatched values left in big table : (1162, 6)\n",
      "Big table number of wings left beginning by g : (399, 6)\n",
      "Dat folder number of wings left beginning by g : (401, 6)\n",
      "Difference : -2\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')\n",
    "big_g, dat_g = get_letter_group(df_dat_left, df_big_left, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gottingen = [lambda x : (re.sub(\"\\s\", \"\", str(x))), lambda x : (re.sub('\\(.*?\\)', \"\", str(x)))]\n",
    "big_g = try_pattern_family(big_g, 'Gottingen', gottingen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name_big', 'Family', 'Name_modified', 'First letter',\n",
      "       'Name_modified_by_pattern', 'Name_modified_by_family'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_big_left = incorporate_family_pattern(df_big_left, big_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 1162 valeurs dont 372 correspondent aux fichiers dat.\n",
      "Il reste 790 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "# we already did a merge so maybe just add an argument precising the on merge column\n",
    "# By merging using 'left', we obtain 4905 correspondances\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Global regex with quick manual verif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1781, 6)\n",
      "Unmatched values left in big table : (790, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))), lambda x : (re.sub(\"-\", \"\", str(x))), lambda x : (re.sub(\"%\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 790 valeurs dont 245 correspondent aux fichiers dat.\n",
      "Il reste 545 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Uncategorized            100\n",
      "NASA                      49\n",
      "Hepperle                  49\n",
      "Selig et. al.             48\n",
      "Quabeck                   42\n",
      "Leinauer                  25\n",
      "Wortmann                  22\n",
      "NACA/Munk                 22\n",
      "Boeing                    19\n",
      "Barth                     16\n",
      "Gulfstream                14\n",
      "Lockheed                  14\n",
      "NACA                      13\n",
      "Pflug                     12\n",
      "Althaus                   11\n",
      "Gottingen                  9\n",
      "Drela                      9\n",
      "Sikorsky                   8\n",
      "Girsberger                 7\n",
      "Onera                      7\n",
      "Marske                     6\n",
      "Scherrer                   6\n",
      "Siegmann                   5\n",
      "NACA 64-series             5\n",
      "Delft                      5\n",
      "NACA 63-series             4\n",
      "Hammond                    4\n",
      "TsAGI                      3\n",
      "RAF                        2\n",
      "NACA 4-digit modified      2\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. keep trying**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1536, 6)\n",
      "Unmatched values left in big table : (545, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\.\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\",\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"/\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"-\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"_\", \"\", str(x))),  \n",
    "                 lambda x : (re.sub(\"%\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\)\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb 96 12.7/3.0\t pas fonctionné df_big_left sb9612730  sb96127_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 545 valeurs dont 126 correspondent aux fichiers dat.\n",
      "Il reste 419 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Uncategorized            89\n",
      "Hepperle                 49\n",
      "Selig et. al.            48\n",
      "Leinauer                 25\n",
      "NACA/Munk                22\n",
      "NASA                     20\n",
      "Boeing                   19\n",
      "Wortmann                 19\n",
      "Lockheed                 14\n",
      "Gulfstream               14\n",
      "NACA                     13\n",
      "Althaus                  11\n",
      "Drela                     9\n",
      "Gottingen                 9\n",
      "Sikorsky                  8\n",
      "Onera                     7\n",
      "Girsberger                6\n",
      "Marske                    6\n",
      "NACA 64-series            5\n",
      "Delft                     4\n",
      "Hammond                   4\n",
      "NACA 63-series            4\n",
      "RAF                       2\n",
      "NACA 4-digit modified     2\n",
      "Quabeck                   2\n",
      "Egglestone                2\n",
      "Clark                     2\n",
      "NPL                       1\n",
      "TsAGI                     1\n",
      "USA                       1\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8. Smooth -> sm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1410, 6)\n",
      "Unmatched values left in big table : (419, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_smooth = df_big_left.loc[df_big_left['Name_modified'].str.contains('smooth'), 'Name_modified'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\.\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\",\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"/\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"-\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"_\", \"\", str(x))),  \n",
    "                 lambda x : (re.sub(\"%\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\)\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"smoothed\", \"sm\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 419 valeurs dont 13 correspondent aux fichiers dat.\n",
      "Il reste 406 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exceptions\n",
    "# list_smoothed = df_merge.loc[df_merge['Name_modified_dat'].isna()==False, 'Name_modified_big'].to_list()\n",
    "# nasmooth = [name for name in list_smooth if name not in list_smoothed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Removing whats between parenthesis with manual verif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1397, 6)\n",
      "Unmatched values left in big table : (406, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New columns to be created normally !!!!\n",
    "pattern_global =[lambda x : (re.sub('\\(.*?\\)', \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\s\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)\n",
    "\n",
    "df_big_left['parenthesis_content'] = df_big_left['Name_modified'].copy()\n",
    "df_big_left['parenthesis_content'] = df_big_left.loc[:, 'parenthesis_content'].apply(lambda x : (re.findall('\\(.*?\\)', str(x))))\n",
    "df_dat_left['parenthesis_content'] = df_dat_left['Name_modified'].copy()\n",
    "df_dat_left['parenthesis_content'] = df_dat_left.loc[:, 'parenthesis_content'].apply(lambda x : (re.findall('\\(.*?\\)', str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 406 valeurs dont 29 correspondent aux fichiers dat.\n",
      "Il reste 377 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Uncategorized    70\n",
      "Hepperle         49\n",
      "Selig et. al.    28\n",
      "Leinauer         25\n",
      "NACA/Munk        22\n",
      "NASA             20\n",
      "Wortmann         19\n",
      "Boeing           19\n",
      "Gulfstream       14\n",
      "Lockheed         14\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge[['Name_big', 'Family', 'Name_modified_by_pattern', 'parenthesis_content_big', 'Name_modified_dat', 'Name_dat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Hepperle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1368, 7)\n",
      "Unmatched values left in big table : (377, 7)\n",
      "Big table number of wings left beginning by m : (57, 7)\n",
      "Dat folder number of wings left beginning by m : (86, 7)\n",
      "Difference : -29\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')\n",
    "big_m, dat_m = get_letter_group(df_dat_left, df_big_left, 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emeline\\AppData\\Local\\Temp\\ipykernel_17776\\3852149944.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  big_m.loc[big_m['Family'] == \"Hepperle\", 'Name_modified_by_family'] = big_m.loc[big_m['Family'] == \"Hepperle\", 'Name_modified'].copy()\n"
     ]
    }
   ],
   "source": [
    "hepperle = [lambda x : (((re.split(\"\\s\", str(x)))[0])+(re.split(\"\\s\", str(x)))[1])]\n",
    "big_m.loc[big_m['Family'] == \"Hepperle\", 'Name_modified_by_family'] = big_m.loc[big_m['Family'] == \"Hepperle\", 'Name_modified'].copy()\n",
    "big_m = try_pattern_family(big_m, 'Hepperle', hepperle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name_big', 'Family', 'Name_modified', 'First letter',\n",
      "       'Name_modified_by_pattern', 'parenthesis_content',\n",
      "       'Name_modified_by_family'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_big_left = incorporate_family_pattern(df_big_left, big_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 377 valeurs dont 49 correspondent aux fichiers dat.\n",
      "Il reste 328 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family NACA/Munk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1319, 7)\n",
      "Unmatched values left in big table : (328, 7)\n",
      "Big table number of wings left beginning by n : (55, 7)\n",
      "Dat folder number of wings left beginning by n : (1023, 7)\n",
      "Difference : -968\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')\n",
    "big_n, dat_n = get_letter_group(df_dat_left, df_big_left, 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name_big', 'Family', 'Name_modified', 'First letter',\n",
      "       'Name_modified_by_pattern', 'parenthesis_content',\n",
      "       'Name_modified_by_family'],\n",
      "      dtype='object')\n",
      "Le dataset contient 328 valeurs dont 22 correspondent aux fichiers dat.\n",
      "Il reste 306 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "nacamunk = [lambda x : (re.sub(\"naca\",\"\", str(x))), lambda x : (re.sub(\"\\s\", \"\", str(x)))]\n",
    "big_n = try_pattern_family(big_n, 'NACA/Munk', nacamunk)\n",
    "df_big_left = incorporate_family_pattern(df_big_left, big_n)\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')\n",
    "df_dat_left.drop(df_dat_left[df_dat_left['Name_modified'].str.contains('naca')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (318, 7)\n",
      "Unmatched values left in big table : (306, 7)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 306 valeurs dont 14 correspondent aux fichiers dat.\n",
      "Il reste 292 valeurs à matcher.\n",
      "Unmatched values left in the dat folder : (304, 7)\n",
      "Unmatched values left in big table : (292, 7)\n"
     ]
    }
   ],
   "source": [
    "# As much of giii rows in both dataset its the Gulfstream family \n",
    "giii_dat = df_dat_left[df_dat_left['Name_modified'].str.contains(\"giii\")]\n",
    "giii_big = df_big_left[df_big_left['Name_modified'].str.contains(\"giii\")]\n",
    "giinb = giii_big['Name_modified'].apply(lambda x : (re.findall('\\d+', str(x))))\n",
    "giinb = [int(nb[0]) for nb in giinb.values]\n",
    "giinb = sorted(giinb)\n",
    "giiiletter = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n']\n",
    "dict_giii = {}\n",
    "[dict_giii.update({('giiibl'+str(nb)) : ('giii'+str(letter))}) for nb, letter in zip(giinb, giiiletter)]\n",
    "df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified_by_pattern'].map(dict_giii).fillna(df_big_left['Name_modified_by_pattern'])\n",
    "\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')\n",
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_big_left['First letter'].value_counts()\n",
    "# df_dat_left['First letter'].value_counts()\n",
    "# df_big_left['First letter'].value_counts() - df_dat_left['First letter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\.\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\",\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"/\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"-\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"_\", \"\", str(x))),  \n",
    "                 lambda x : (re.sub(\"%\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\)\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"smoothed\", \"sm\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_left.to_csv('data/df_dat_left.csv')\n",
    "df_big_left.to_csv('data/df_big_left.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
