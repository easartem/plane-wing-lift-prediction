{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV and check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 8353 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8353, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a18.DAT</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a18sm.DAT</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A6014-S.DAT</td>\n",
       "      <td>6116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6016-S.DAT</td>\n",
       "      <td>5914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A6018-S.DAT</td>\n",
       "      <td>5889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Size\n",
       "0      a18.DAT   945\n",
       "1    a18sm.DAT  1795\n",
       "2  A6014-S.DAT  6116\n",
       "3  A6016-S.DAT  5914\n",
       "4  A6018-S.DAT  5889"
      ]
     },
     "execution_count": 2123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat = pd.read_csv('dat_files_index.csv', usecols=('name', 'size'))\n",
    "df_dat.rename(columns={'name':'Name', 'size':'Size'}, inplace=True)\n",
    "print(df_dat.shape)\n",
    "df_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons dans la bigtable : 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Checking if the dataset contains duplicates\n",
    "doublon_datfile = df_dat['Name'].value_counts().index[df_dat['Name'].value_counts().values > 1]\n",
    "print(f'Nombre de doublons dans la bigtable : {len(doublon_datfile)}')\n",
    "print([i for i in doublon_datfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6324, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63A108 MOD C</td>\n",
       "      <td>NASA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A18</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A18 (SMOOTHED)</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6014-S</td>\n",
       "      <td>Ayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A6016-S</td>\n",
       "      <td>Ayers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name         Family\n",
       "0    63A108 MOD C           NASA\n",
       "1             A18  Uncategorized\n",
       "2  A18 (SMOOTHED)  Uncategorized\n",
       "3         A6014-S          Ayers\n",
       "4         A6016-S          Ayers"
      ]
     },
     "execution_count": 2125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigtable = pd.read_csv('data/ailes_avion.csv', usecols=('Name', 'Family'))\n",
    "print(df_bigtable.shape)\n",
    "df_bigtable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons dans la bigtable : 2\n",
      "['FX 66-17AII-182', 'BOEING 737 MIDSPAN']\n"
     ]
    }
   ],
   "source": [
    "# Checking if the dataset contains duplicates\n",
    "doublon_bigtable = df_bigtable['Name'].value_counts().index[df_bigtable['Name'].value_counts().values > 1]\n",
    "print(f'Nombre de doublons dans la bigtable : {len(doublon_bigtable)}')\n",
    "print([i for i in doublon_bigtable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Basic Regex and exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column Name_modified with all names in lowercase and without the .DAT ending \n",
    "df_dat['Name_modified'] =  df_dat['Name'].apply(lambda x : (re.split(\".DAT$\", str(x)))[0])\n",
    "df_dat['Name_modified'] = df_dat['Name_modified'].apply(lambda x : str(x).lower())\n",
    "# Create a column Name_modified with all names in lowercase\n",
    "df_bigtable['Name_modified'] = df_bigtable['Name'].apply(lambda x : str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual affectation of the duplicates after verification\n",
    "df_bigtable.loc[596, ['Name_modified']] = 'fx6617ai'\n",
    "df_bigtable.loc[597, ['Name_modified']] = 'fx6617a2'\n",
    "df_bigtable.loc[154, ['Name_modified']] = 'b737c'\n",
    "df_bigtable.loc[155, ['Name_modified']] = 'b737b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family exceptions beginning by 'g'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'gu25-5(11)8', 'Name_modified'] = 'gu255118'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'gs-1', 'Name_modified'] = 'gs1'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'griffith 30% suction airfoil', 'Name_modified'] = 'griffith30symsuction'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'goe 167 (v.karman prop.2)', 'Name_modified'] = 'goe167'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'glenn martin 2', 'Name_modified'] = 'glennmartin2'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'glenn martin 3', 'Name_modified'] = 'glennmartin3'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'glenn martin 4', 'Name_modified'] = 'glennmartin4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge both dataset, return merge\n",
    "def merge_df(df_bigtable, df_dat, on_column):\n",
    "    df_merge = pd.merge(df_bigtable, df_dat, on=on_column, how='left', suffixes=('_big', '_dat'))\n",
    "    nb_mismatch = df_merge[df_merge['Name_dat'].isna()].shape[0]\n",
    "    nb_match = df_merge.shape[0] - nb_mismatch\n",
    "    print(f'Le dataset contient {df_merge.shape[0]} valeurs dont {nb_match} correspondent aux fichiers dat.')\n",
    "    print(f'Il reste {nb_mismatch} valeurs Ã  matcher.')\n",
    "    df_merge.head()\n",
    "    return df_merge\n",
    "\n",
    "# Function to evaluate the missing values per family\n",
    "def groupna_family(df_merge):\n",
    "    family = df_merge.groupby(['Family']).count()\n",
    "    mask_family = (family['Name_big'] != family['Name_dat'])\n",
    "    family_na = family[mask_family].copy()\n",
    "    family_na['nb_na'] = family_na['Name_big'] - family_na['Size']\n",
    "    # We are interested by the 5 families with the most of na\n",
    "    print(family_na['nb_na'].sort_values(ascending=False).head(5))\n",
    "\n",
    "# Function to iinitialize df_big et df_dat\n",
    "# We want to look through the wings left in each dataframe in order to avoid corrupting good matchs\n",
    "\n",
    "def initiate_df_left(df_bigtable, df_dat, df_merge):\n",
    "    # Create df_dat_left and df_big_left\n",
    "    df_dat_left = pd.merge(df_bigtable, df_dat, on='Name_modified', how='right', suffixes=('_big', '_dat'))\n",
    "    df_dat_left = df_dat_left[df_dat_left['Name_big'].isna()].copy()\n",
    "    print(f\"Unmatched values left in the dat folder : {df_dat_left.shape}\")\n",
    "    df_big_left = df_merge[df_merge['Name_dat'].isna()].copy()\n",
    "    print(f\"Unmatched values left in big table : {df_big_left.shape}\")\n",
    "\n",
    "    # Create a new column for each df containing the first letter of each wing\n",
    "    df_dat_left['First letter'] = [x[0] for x in df_dat_left['Name_modified'].values]\n",
    "    df_big_left['First letter'] = [x[0] for x in df_big_left['Name_modified'].values]\n",
    "\n",
    "    # Create a new column for each df with z copy of the modified name to further work on\n",
    "    df_dat_left['Name_modified_by_family'] = df_dat_left['Name_modified'].copy()\n",
    "    df_big_left['Name_modified_by_family'] = df_big_left['Name_modified'].copy()\n",
    "\n",
    "    # Create a new column for each df with z copy of the modified name to further work on\n",
    "    df_dat_left['Name_modified_by_pattern'] = df_dat_left['Name_modified'].copy()\n",
    "    df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified'].copy()\n",
    "\n",
    "\n",
    "    # df_dat_left ----> ['Name_big', 'Family', 'Name_modified', 'Name_dat', 'Size', 'First letter', 'Name_modified_by_family']\n",
    "    # Name_big and Family are NaN\n",
    "    df_dat_left.drop(columns=['Name_big', 'Family'], inplace=True)\n",
    "    # df_big_left ----> ['Name_big', 'Family', 'Name_modified', 'Name_dat', 'Size', 'First letter', 'Name_modified_by_family']\n",
    "    # Name_dat and Size are NaN\n",
    "    df_big_left.drop(columns=['Name_dat', 'Size'], inplace=True)\n",
    "\n",
    "    return df_dat_left, df_big_left\n",
    "\n",
    "# Function to create filter by letter\n",
    "def get_letter_group(df_dat_left, df_big_left, letter):\n",
    "    big_letter = df_big_left[df_big_left['First letter'] == letter]\n",
    "    dat_letter = df_dat_left[df_dat_left['First letter'] == letter]\n",
    "    print(f'Big table number of wings left beginning by {letter} : {big_letter.shape}')\n",
    "    print(f'Dat folder number of wings left beginning by {letter} : {dat_letter.shape}')\n",
    "    print(f'Difference : {big_letter.shape[0] - dat_letter.shape[0]}')\n",
    "    return big_letter, dat_letter\n",
    "\n",
    "# Function to pass through pattern\n",
    "def try_pattern_family(big_letter, family, pattern_list):\n",
    "    big_letter = big_letter.copy()\n",
    "    for pattern in pattern_list:\n",
    "        # Apply pattern\n",
    "        big_letter.loc[big_letter['Family'] == family, 'Name_modified_by_family'] = big_letter.loc[big_letter['Family'] == family, 'Name_modified_by_family'].apply(pattern)\n",
    "    return big_letter\n",
    "\n",
    "# Function to incorporate the new name found (Name_modified_by_family) into the dataset with the bigtable wings left to match\n",
    "def incorporate_family_pattern(df_big_left, big_letter):\n",
    "    df_big_left = pd.merge(df_big_left, big_letter[['Name_big', 'Name_modified_by_family']], on='Name_big', how='left', suffixes=('_left', '_big'))\n",
    "    df_big_left['Name_modified_by_family_big'] = df_big_left['Name_modified_by_family_big'].fillna(df_big_left['Name_modified_by_family_left'])\n",
    "    df_big_left.drop([\"Name_modified_by_family_left\"], inplace=True, axis=1)\n",
    "    df_big_left.rename(columns={'Name_modified_by_family_big':'Name_modified_by_family'}, inplace=True)\n",
    "    print(df_big_left.columns)\n",
    "    return df_big_left\n",
    "\n",
    "def set_df_left(df_dat_left, df_merge, on_column):\n",
    "    # Create df_dat_left and df_big_left\n",
    "    df_dat_left = pd.merge(df_merge, df_dat_left, on=on_column, how='right', suffixes=('_big', '_dat'))\n",
    "    df_dat_left = df_dat_left[df_dat_left['Name_big'].isna()]\n",
    "    df_dat_left.dropna(axis=1, how='all', inplace=True)\n",
    "    df_dat_left = df_dat_left.set_axis([re.sub('_dat', \"\", str(col)) for col in df_dat_left.columns], axis=1)\n",
    "    df_dat_left.rename(columns={'Name':'Name_dat'}, inplace=True)\n",
    "    print(f\"Unmatched values left in the dat folder : {df_dat_left.shape}\")\n",
    "    df_big_left = df_merge[df_merge['Name_dat'].isna()].copy()\n",
    "    df_big_left.dropna(axis=1, how='all', inplace=True)\n",
    "    df_big_left = df_big_left.set_axis([re.sub('_big', \"\", str(col)) for col in df_big_left.columns], axis=1)\n",
    "    df_big_left.rename(columns={'Name':'Name_big'}, inplace=True)\n",
    "    print(f\"Unmatched values left in big table : {df_big_left.shape}\")\n",
    "    return df_dat_left, df_big_left\n",
    "\n",
    "def try_pattern(df_big_left, df_dat_left, pattern_list):\n",
    "    df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified'].copy()\n",
    "    df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified'].copy()\n",
    "\n",
    "    for pattern in pattern_list:\n",
    "        df_big_left['Name_modified_by_pattern'] = df_big_left.loc[:, 'Name_modified_by_pattern'].apply(pattern)\n",
    "        df_dat_left['Name_modified_by_pattern'] = df_dat_left.loc[:, 'Name_modified_by_pattern'].apply(pattern)\n",
    "\n",
    "    return df_dat_left, df_big_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 6324 valeurs dont 4916 correspondent aux fichiers dat.\n",
      "Il reste 1408 valeurs Ã  matcher.\n",
      "Family\n",
      "Gottingen        381\n",
      "Eppler           201\n",
      "Uncategorized    147\n",
      "Wortmann         110\n",
      "NASA              54\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_function = merge_df(df_bigtable, df_dat, 'Name_modified')\n",
    "groupna_family(test_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Create dataframes with wings left to match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (3437, 5)\n",
      "Unmatched values left in big table : (1408, 5)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = initiate_df_left(df_bigtable, df_dat, test_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Regex to match the family Yost,Eiffel,Eppeler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big table number of wings left beginning by e : (221, 6)\n",
      "Dat folder number of wings left beginning by e : (219, 6)\n",
      "Difference : 2\n"
     ]
    }
   ],
   "source": [
    "big_e, dat_e = get_letter_group(df_dat_left, df_big_left, 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2134,
   "metadata": {},
   "outputs": [],
   "source": [
    "yost = [lambda x : (re.sub(\"\\s\", \"\", str(x))), lambda x : (re.sub(\"\\.\", \"\", str(x))), lambda x : (re.sub(\"/\", \"\", str(x)))]\n",
    "eiffel = [lambda x : (re.sub('\\(.*?\\)', \"\", str(x))), lambda x : (re.sub(\"\\s\", \"\", str(x))), lambda x : (re.split(\"-\", str(x)))[0]]\n",
    "eppler = [lambda x : (re.sub(\"eppler\", \"e\", str(x))), lambda x : (re.sub(\"\\s\", \"\", str(x)))]\n",
    "big_e = try_pattern_family(big_e, 'Yost', yost)\n",
    "big_e = try_pattern_family(big_e, 'Eiffel', eiffel)\n",
    "big_e = try_pattern_family(big_e, 'Eppler', eppler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name_big', 'Family', 'Name_modified', 'First letter',\n",
      "       'Name_modified_by_pattern', 'Name_modified_by_family'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Function to incorporate the new name found (Name_modified_by_family) into the dataset with the bigtable wings left to match\n",
    "df_big_left = incorporate_family_pattern(df_big_left, big_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 1408 valeurs dont 199 correspondent aux fichiers dat.\n",
      "Il reste 1209 valeurs Ã  matcher.\n"
     ]
    }
   ],
   "source": [
    "# we already did a merge so maybe just add an argument precising the on merge column\n",
    "# By merging using 'left', we obtain 4905 correspondances\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Regex to match the family Gottingen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (3238, 6)\n",
      "Unmatched values left in big table : (1209, 6)\n",
      "Big table number of wings left beginning by g : (399, 6)\n",
      "Dat folder number of wings left beginning by g : (401, 6)\n",
      "Difference : -2\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')\n",
    "big_g, dat_g = get_letter_group(df_dat_left, df_big_left, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2138,
   "metadata": {},
   "outputs": [],
   "source": [
    "gottingen = [lambda x : (re.sub(\"\\s\", \"\", str(x))), lambda x : (re.sub('\\(.*?\\)', \"\", str(x)))]\n",
    "big_g = try_pattern_family(big_g, 'Gottingen', gottingen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name_big', 'Family', 'Name_modified', 'First letter',\n",
      "       'Name_modified_by_pattern', 'Name_modified_by_family'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_big_left = incorporate_family_pattern(df_big_left, big_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 1209 valeurs dont 372 correspondent aux fichiers dat.\n",
      "Il reste 837 valeurs Ã  matcher.\n"
     ]
    }
   ],
   "source": [
    "# we already did a merge so maybe just add an argument precising the on merge column\n",
    "# By merging using 'left', we obtain 4905 correspondances\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Global regex with quick manual verif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (2866, 6)\n",
      "Unmatched values left in big table : (837, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))), lambda x : (re.sub(\"-\", \"\", str(x))), lambda x : (re.sub(\"%\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 837 valeurs dont 245 correspondent aux fichiers dat.\n",
      "Il reste 592 valeurs Ã  matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. keep trying**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (2621, 6)\n",
      "Unmatched values left in big table : (592, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\.\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"/\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"-\", \"\", str(x))), \n",
    "                 lambda x : (re.sub(\"%\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\)\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 592 valeurs dont 86 correspondent aux fichiers dat.\n",
      "Il reste 506 valeurs Ã  matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Uncategorized    99\n",
      "Hepperle         49\n",
      "Selig et. al.    48\n",
      "Boeing           32\n",
      "Leinauer         25\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8. Smooth -> sm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (2535, 6)\n",
      "Unmatched values left in big table : (506, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2149,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_smooth = df_big_left.loc[df_big_left['Name_modified'].str.contains('smooth'), 'Name_modified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"smoothed\", \"sm\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\.\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"/\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"-\", \"\", str(x))), \n",
    "                 lambda x : (re.sub(\"%\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\)\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 506 valeurs dont 13 correspondent aux fichiers dat.\n",
      "Il reste 493 valeurs Ã  matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a18 (smoothed)',\n",
       " 'be50 (smoothed)',\n",
       " 'ch10 (smoothed)',\n",
       " 'davis (smoothed)',\n",
       " 'gemini (smoothed)',\n",
       " 'gm15 (smoothed)',\n",
       " 'goe 795 smoothed',\n",
       " 'k3311 (smoothed)',\n",
       " 'ma409 (smoothed)',\n",
       " 'pmc19 smoothed',\n",
       " 'tsagi p-ii (15.5%) smoothed',\n",
       " 'ua(2)-180 smoothed',\n",
       " 'wasp (smoothed)']"
      ]
     },
     "execution_count": 2152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_smoothed = df_merge.loc[df_merge['Name_modified_dat'].isna()==False, 'Name_modified_big'].to_list()\n",
    "list_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Removing parenthesis while keeping the inside content**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (2522, 6)\n",
      "Unmatched values left in big table : (493, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New columns to be created normally !!!!\n",
    "pattern_global =[lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\)\", \"\", str(x)))\n",
    "                 ]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 493 valeurs dont 0 correspondent aux fichiers dat.\n",
      "Il reste 493 valeurs Ã  matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Uncategorized    88\n",
      "Hepperle         49\n",
      "Selig et. al.    48\n",
      "Boeing           32\n",
      "Leinauer         25\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Removing whats between parenthesis with manual verif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (2522, 6)\n",
      "Unmatched values left in big table : (493, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New columns to be created normally !!!!\n",
    "pattern_global =[lambda x : (re.sub('\\(.*?\\)', \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\s\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)\n",
    "\n",
    "df_big_left['parenthesis_content'] = df_big_left['Name_modified'].copy()\n",
    "df_big_left['parenthesis_content'] = df_big_left.loc[:, 'parenthesis_content'].apply(lambda x : (re.findall('\\(.*?\\)', str(x))))\n",
    "df_dat_left['parenthesis_content'] = df_dat_left['Name_modified'].copy()\n",
    "df_dat_left['parenthesis_content'] = df_dat_left.loc[:, 'parenthesis_content'].apply(lambda x : (re.findall('\\(.*?\\)', str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name_big                    AG44CT -02F\n",
       "Family                            Drela\n",
       "Name_modified               ag44ct -02f\n",
       "First letter                          a\n",
       "Name_modified_by_pattern     ag44ct-02f\n",
       "Name_modified_by_family     ag44ct -02f\n",
       "parenthesis_content                  []\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 2159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_left.loc[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 493 valeurs dont 30 correspondent aux fichiers dat.\n",
      "Il reste 463 valeurs Ã  matcher.\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Uncategorized    79\n",
      "Hepperle         49\n",
      "Boeing           32\n",
      "Selig et. al.    28\n",
      "Leinauer         25\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge[['Name_big', 'Family', 'Name_modified_by_pattern', 'parenthesis_content_big', 'Name_modified_dat', 'Name_dat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# get duplicates in Name_dat of df_merge\n",
    "duplicates_without_parenthesis = df_merge['Name_modified_dat'].value_counts().index[df_merge['Name_modified_dat'].value_counts().values > 1].to_list()\n",
    "print(duplicates_without_parenthesis)\n",
    "# Get their index\n",
    "index_duplicates_without_parenthesis = [df_merge[df_merge['Name_modified_dat'] == name].index for name in duplicates_without_parenthesis]\n",
    "index_list = []\n",
    "for index in index_duplicates_without_parenthesis:\n",
    "    index_list.append(index[0])\n",
    "    index_list.append(index[1])\n",
    "print(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_big</th>\n",
       "      <th>Family</th>\n",
       "      <th>Name_modified_big</th>\n",
       "      <th>First letter_big</th>\n",
       "      <th>Name_modified_by_pattern</th>\n",
       "      <th>Name_modified_by_family_big</th>\n",
       "      <th>parenthesis_content_big</th>\n",
       "      <th>Name_modified_by_family_dat</th>\n",
       "      <th>Name_modified_dat</th>\n",
       "      <th>Name_dat</th>\n",
       "      <th>Size</th>\n",
       "      <th>First letter_dat</th>\n",
       "      <th>parenthesis_content_dat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name_big, Family, Name_modified_big, First letter_big, Name_modified_by_pattern, Name_modified_by_family_big, parenthesis_content_big, Name_modified_by_family_dat, Name_modified_dat, Name_dat, Size, First letter_dat, parenthesis_content_dat]\n",
       "Index: []"
      ]
     },
     "execution_count": 2164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.loc[index_list, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2165,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2165], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_dat_left[df_dat_left[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName_modified\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(duplicates_without_parenthesis[\u001b[38;5;241m0\u001b[39m])]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df_dat_left[df_dat_left['Name_modified'].str.contains(duplicates_without_parenthesis[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_modified_by_pattern</th>\n",
       "      <th>Name_modified_by_family</th>\n",
       "      <th>Name_modified</th>\n",
       "      <th>Name_dat</th>\n",
       "      <th>Size</th>\n",
       "      <th>First letter</th>\n",
       "      <th>parenthesis_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>k3311</td>\n",
       "      <td>k3311</td>\n",
       "      <td>k3311</td>\n",
       "      <td>k3311.DAT</td>\n",
       "      <td>1140</td>\n",
       "      <td>k</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>k3311sm</td>\n",
       "      <td>k3311sm</td>\n",
       "      <td>k3311sm</td>\n",
       "      <td>k3311sm.DAT</td>\n",
       "      <td>1814</td>\n",
       "      <td>k</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name_modified_by_pattern Name_modified_by_family Name_modified  \\\n",
       "1252                    k3311                   k3311         k3311   \n",
       "1253                  k3311sm                 k3311sm       k3311sm   \n",
       "\n",
       "         Name_dat  Size First letter parenthesis_content  \n",
       "1252    k3311.DAT  1140            k                  []  \n",
       "1253  k3311sm.DAT  1814            k                  []  "
      ]
     },
     "execution_count": 1885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat_left[df_dat_left['Name_modified'].str.contains(duplicates_without_parenthesis[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_modified_by_pattern</th>\n",
       "      <th>Name_modified_by_family</th>\n",
       "      <th>Name_modified</th>\n",
       "      <th>Name_dat</th>\n",
       "      <th>Size</th>\n",
       "      <th>First letter</th>\n",
       "      <th>parenthesis_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>ma409</td>\n",
       "      <td>ma409</td>\n",
       "      <td>ma409</td>\n",
       "      <td>ma409.DAT</td>\n",
       "      <td>962</td>\n",
       "      <td>m</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>ma409sm</td>\n",
       "      <td>ma409sm</td>\n",
       "      <td>ma409sm</td>\n",
       "      <td>ma409sm.DAT</td>\n",
       "      <td>1794</td>\n",
       "      <td>m</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name_modified_by_pattern Name_modified_by_family Name_modified  \\\n",
       "1299                    ma409                   ma409         ma409   \n",
       "1300                  ma409sm                 ma409sm       ma409sm   \n",
       "\n",
       "         Name_dat  Size First letter parenthesis_content  \n",
       "1299    ma409.DAT   962            m                  []  \n",
       "1300  ma409sm.DAT  1794            m                  []  "
      ]
     },
     "execution_count": 1886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat_left[df_dat_left['Name_modified'].str.contains(duplicates_without_parenthesis[2])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
