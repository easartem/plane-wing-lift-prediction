{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV and check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 8353 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8353, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a18.DAT</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a18sm.DAT</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A6014-S.DAT</td>\n",
       "      <td>6116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6016-S.DAT</td>\n",
       "      <td>5914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A6018-S.DAT</td>\n",
       "      <td>5889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name  Size\n",
       "0      a18.DAT   945\n",
       "1    a18sm.DAT  1795\n",
       "2  A6014-S.DAT  6116\n",
       "3  A6016-S.DAT  5914\n",
       "4  A6018-S.DAT  5889"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat = pd.read_csv('data/dat_files_index.csv', usecols=('name', 'size'))\n",
    "df_dat.rename(columns={'name':'Name', 'size':'Size'}, inplace=True)\n",
    "print(df_dat.shape)\n",
    "df_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons dans la bigtable : 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Checking if the dataset contains duplicates\n",
    "doublon_datfile = df_dat['Name'].value_counts().index[df_dat['Name'].value_counts().values > 1]\n",
    "print(f'Nombre de doublons dans la bigtable : {len(doublon_datfile)}')\n",
    "print([i for i in doublon_datfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6324, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63A108 MOD C</td>\n",
       "      <td>NASA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A18</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A18 (SMOOTHED)</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6014-S</td>\n",
       "      <td>Ayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A6016-S</td>\n",
       "      <td>Ayers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name         Family\n",
       "0    63A108 MOD C           NASA\n",
       "1             A18  Uncategorized\n",
       "2  A18 (SMOOTHED)  Uncategorized\n",
       "3         A6014-S          Ayers\n",
       "4         A6016-S          Ayers"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bigtable = pd.read_csv('data/ailes_avion.csv', usecols=('Name', 'Family'))\n",
    "print(df_bigtable.shape)\n",
    "df_bigtable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons dans la bigtable : 2\n",
      "['FX 66-17AII-182', 'BOEING 737 MIDSPAN']\n"
     ]
    }
   ],
   "source": [
    "# Checking if the dataset contains duplicates\n",
    "doublon_bigtable = df_bigtable['Name'].value_counts().index[df_bigtable['Name'].value_counts().values > 1]\n",
    "print(f'Nombre de doublons dans la bigtable : {len(doublon_bigtable)}')\n",
    "print([i for i in doublon_bigtable])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Basic Regex and exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column Name_modified with all names in lowercase and without the .DAT ending \n",
    "df_dat['Name_modified'] =  df_dat['Name'].apply(lambda x : (re.split(\".DAT$\", str(x)))[0])\n",
    "df_dat['Name_modified'] = df_dat['Name_modified'].apply(lambda x : str(x).lower())\n",
    "# Create a column Name_modified with all names in lowercase\n",
    "df_bigtable['Name_modified'] = df_bigtable['Name'].apply(lambda x : str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual affectation of the duplicates after verification\n",
    "df_bigtable.loc[596, ['Name_modified']] = 'fx6617ai'\n",
    "df_bigtable.loc[597, ['Name_modified']] = 'fx6617a2'\n",
    "df_bigtable.loc[154, ['Name_modified']] = 'b737c'\n",
    "df_bigtable.loc[155, ['Name_modified']] = 'b737b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family exceptions beginning by 'g'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'gu25-5(11)8', 'Name_modified'] = 'gu255118'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'gs-1', 'Name_modified'] = 'gs1'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'griffith 30% suction airfoil', 'Name_modified'] = 'griffith30symsuction'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'goe 167 (v.karman prop.2)', 'Name_modified'] = 'goe167'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'glenn martin 2', 'Name_modified'] = 'glennmartin2'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'glenn martin 3', 'Name_modified'] = 'glennmartin3'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'glenn martin 4', 'Name_modified'] = 'glennmartin4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler 377mod', 'Name_modified'] = 'e377m'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler e193gu-k24', 'Name_modified'] = 'e193gu-k24'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler ste 87(-3)-914', 'Name_modified'] = 'ste87391'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler ste 871-514', 'Name_modified'] = 'ste87151'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'eppler stf 863-615', 'Name_modified'] = 'stf86361'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'aquila 9.3% smoothed', 'Name_modified'] = 'aquilasm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'bergey bw-3 (smoothed)', 'Name_modified'] = 'bw3'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'clark-y 11.7% smoothed', 'Name_modified'] = 'clarkysm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'cody robertson cr 001 r/c hand-launch low reynolds number airfoil (smoothed)', 'Name_modified'] = 'cr001sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'dale house dh4009 (smoothed) used on the storm r/c aerobatic aircraft', 'Name_modified'] = 'dh4009sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'fx 60-100 10.0% smoothed', 'Name_modified'] = 'fx60100sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'fx 63-137 13.7% smoothed', 'Name_modified'] = 'fx63137sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'fx 74-cl5-140 mod (smoothed)', 'Name_modified'] = 'fx74modsm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'mb253515 15.0% smoothed', 'Name_modified'] = 'mb253515sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'r140 12.04% (smoothed)', 'Name_modified'] = 'r140sm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'spica 11.73% smoothed', 'Name_modified'] = 'spicasm'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'usnps4 (smoothed)', 'Name_modified'] = 'usnps4'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'wb-135/35 13.5% smoothed', 'Name_modified'] = 'wb13535sm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .08 span', 'Name_modified'] = 'b707a'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .19 span', 'Name_modified'] = 'b707b'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .40 span', 'Name_modified'] = 'b707c'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .54 span', 'Name_modified'] = 'b707d'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 707 .99 span', 'Name_modified'] = 'b707e'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 103', 'Name_modified'] = 'boe103'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 106', 'Name_modified'] = 'boe106'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 737 root', 'Name_modified'] = 'b737a'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'boeing 737 outboard', 'Name_modified'] = 'b737d'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'kc-135 bl124.32', 'Name_modified'] = 'kc135b'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'kc-135 bl200.76', 'Name_modified'] = 'kc135c'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'kc-135 bl351.6', 'Name_modified'] = 'kc135d'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'kc-135 bl52.44', 'Name_modified'] = 'kc135a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'naca m6 (65%)', 'Name_modified'] = 'm6_65'\n",
    "df_bigtable.loc[df_bigtable['Name_modified'] == 'naca m6 (85%)', 'Name_modified'] = 'm6_85'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge both dataset and return the df merged\n",
    "def merge_df(df_bigtable, df_dat, on_column):\n",
    "    df_merge = pd.merge(df_bigtable, df_dat, on=on_column, how='left', suffixes=('_big', '_dat'))\n",
    "    nb_mismatch = df_merge[df_merge['Name_dat'].isna()].shape[0]\n",
    "    nb_match = df_merge.shape[0] - nb_mismatch\n",
    "    print(f'Le dataset contient {df_merge.shape[0]} valeurs dont {nb_match} correspondent aux fichiers dat.')\n",
    "    print(f'Il reste {nb_mismatch} valeurs à matcher.')\n",
    "    df_merge.head()\n",
    "    return df_merge\n",
    "\n",
    "\n",
    "# Function to get the list of family fully matched\n",
    "def get_family_done(df_merge, nb):\n",
    "    family = df_merge.groupby(['Family']).count()\n",
    "    mask_family = (family['Name_big'] == family['Name_dat'])\n",
    "    res = family[mask_family].Name_big.sort_values(ascending=False).head(nb)\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "# Function to get the list of missing values per family aka mismatch\n",
    "def groupna_family(df_merge, nb):\n",
    "    family = df_merge.groupby(['Family']).count()\n",
    "    mask_family = (family['Name_big'] != family['Name_dat'])\n",
    "    family_na = family[mask_family].copy()\n",
    "    family_na['nb_na'] = family_na['Name_big'] - family_na['Size']\n",
    "    # We are interested by the 'nb' families with the most of na\n",
    "    print(family_na['nb_na'].sort_values(ascending=False).head(nb))\n",
    "\n",
    "\n",
    "# Function to iinitialize df_big et df_dat\n",
    "# We want to look through the wings left in each dataframe in order to avoid corrupting good matchs\n",
    "def initiate_df_left(df_bigtable, df_dat, df_merge):\n",
    "    # Create df_dat_left and df_big_left\n",
    "    df_dat_left = pd.merge(df_bigtable, df_dat, on='Name_modified', how='right', suffixes=('_big', '_dat'))\n",
    "    df_dat_left = df_dat_left[df_dat_left['Name_big'].isna()].copy()\n",
    "    print(f\"Unmatched values left in the dat folder : {df_dat_left.shape}\")\n",
    "    df_big_left = df_merge[df_merge['Name_dat'].isna()].copy()\n",
    "    print(f\"Unmatched values left in big table : {df_big_left.shape}\")\n",
    "\n",
    "    # Create a new column for each df containing the first letter of each wing\n",
    "    df_dat_left['First letter'] = [x[0] for x in df_dat_left['Name_modified'].values]\n",
    "    df_big_left['First letter'] = [x[0] for x in df_big_left['Name_modified'].values]\n",
    "\n",
    "    # Create a new column for each df with z copy of the modified name to further work on\n",
    "    df_dat_left['Name_modified_by_family'] = df_dat_left['Name_modified'].copy()\n",
    "    df_big_left['Name_modified_by_family'] = df_big_left['Name_modified'].copy()\n",
    "\n",
    "    # Create a new column for each df with z copy of the modified name to further work on\n",
    "    df_dat_left['Name_modified_by_pattern'] = df_dat_left['Name_modified'].copy()\n",
    "    df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified'].copy()\n",
    "\n",
    "\n",
    "    # df_dat_left ----> ['Name_big', 'Family', 'Name_modified', 'Name_dat', 'Size', 'First letter', 'Name_modified_by_family']\n",
    "    # Name_big and Family are NaN\n",
    "    df_dat_left.drop(columns=['Name_big', 'Family'], inplace=True)\n",
    "    # df_big_left ----> ['Name_big', 'Family', 'Name_modified', 'Name_dat', 'Size', 'First letter', 'Name_modified_by_family']\n",
    "    # Name_dat and Size are NaN\n",
    "    df_big_left.drop(columns=['Name_dat', 'Size'], inplace=True)\n",
    "\n",
    "    return df_dat_left, df_big_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to match using specifig family pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create filter by first letter\n",
    "def get_letter_group(df_dat_left, df_big_left, letter):\n",
    "    big_letter = df_big_left[df_big_left['First letter'] == letter]\n",
    "    dat_letter = df_dat_left[df_dat_left['First letter'] == letter]\n",
    "    print(f'Big table number of wings left beginning by {letter} : {big_letter.shape}')\n",
    "    print(f'Dat folder number of wings left beginning by {letter} : {dat_letter.shape}')\n",
    "    print(f'Difference : {big_letter.shape[0] - dat_letter.shape[0]}')\n",
    "    return big_letter, dat_letter\n",
    "\n",
    "\n",
    "# Function to pass through pattern\n",
    "def try_pattern_family(big_letter, family, pattern_list):\n",
    "    big_letter = big_letter.copy()\n",
    "    for pattern in pattern_list:\n",
    "        # Apply pattern\n",
    "        big_letter.loc[big_letter['Family'] == family, 'Name_modified_by_family'] = big_letter.loc[big_letter['Family'] == family, 'Name_modified_by_family'].apply(pattern)\n",
    "    return big_letter\n",
    "\n",
    "\n",
    "# Function to incorporate the new name found (Name_modified_by_family) into the dataset with the bigtable wings left to match\n",
    "def incorporate_family_pattern(df_big_left, big_letter):\n",
    "    df_big_left = pd.merge(df_big_left, big_letter[['Name_big', 'Name_modified_by_family']], on='Name_big', how='left', suffixes=('_left', '_big'))\n",
    "    df_big_left['Name_modified_by_family_big'] = df_big_left['Name_modified_by_family_big'].fillna(df_big_left['Name_modified_by_family_left'])\n",
    "    df_big_left.drop([\"Name_modified_by_family_left\"], inplace=True, axis=1)\n",
    "    df_big_left.rename(columns={'Name_modified_by_family_big':'Name_modified_by_family'}, inplace=True)\n",
    "    return df_big_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to match using global pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_df_left(df_dat_left, df_merge, on_column):\n",
    "    # Create df_dat_left and df_big_left\n",
    "    df_dat_left = pd.merge(df_merge, df_dat_left, on=on_column, how='right', suffixes=('_big', '_dat'))\n",
    "    df_dat_left = df_dat_left[df_dat_left['Name_big'].isna()]\n",
    "    df_dat_left.dropna(axis=1, how='all', inplace=True)\n",
    "    df_dat_left = df_dat_left.set_axis([re.sub('_dat', \"\", str(col)) for col in df_dat_left.columns], axis=1)\n",
    "    df_dat_left.rename(columns={'Name':'Name_dat'}, inplace=True)\n",
    "    print(f\"Unmatched values left in the dat folder : {df_dat_left.shape}\")\n",
    "    df_big_left = df_merge[df_merge['Name_dat'].isna()].copy()\n",
    "    df_big_left.dropna(axis=1, how='all', inplace=True)\n",
    "    df_big_left = df_big_left.set_axis([re.sub('_big', \"\", str(col)) for col in df_big_left.columns], axis=1)\n",
    "    df_big_left.rename(columns={'Name':'Name_big'}, inplace=True)\n",
    "    print(f\"Unmatched values left in big table : {df_big_left.shape}\")\n",
    "    return df_dat_left, df_big_left\n",
    "\n",
    "\n",
    "def try_pattern(df_big_left, df_dat_left, pattern_list):\n",
    "    df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified'].copy()\n",
    "    df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified'].copy()\n",
    "\n",
    "    for pattern in pattern_list:\n",
    "        df_big_left['Name_modified_by_pattern'] = df_big_left.loc[:, 'Name_modified_by_pattern'].apply(pattern)\n",
    "        df_dat_left['Name_modified_by_pattern'] = df_dat_left.loc[:, 'Name_modified_by_pattern'].apply(pattern)\n",
    "\n",
    "    return df_dat_left, df_big_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 6324 valeurs dont 4949 correspondent aux fichiers dat.\n",
      "Il reste 1375 valeurs à matcher.\n",
      "Famille complètes : \n",
      "Family\n",
      "NACA 65-series       608\n",
      "NACA 66-series       604\n",
      "NACA 67-series       548\n",
      "NACA 5-digit         401\n",
      "Habbe                137\n",
      "Horten               133\n",
      "Joukowsky            132\n",
      "Riblett 30-series    114\n",
      "Riblett 40-series    110\n",
      "Riblett 37-series    110\n",
      "Name: Name_big, dtype: int64\n",
      "Nombre de familles total :  68\n"
     ]
    }
   ],
   "source": [
    "df_merge = merge_df(df_bigtable, df_dat, 'Name_modified')\n",
    "print('Famille complètes : ')\n",
    "done_list = get_family_done(df_merge,10)\n",
    "print(\"Nombre de familles total : \", len(df_bigtable['Family'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP only after all matching is done \n",
    "df_dat.drop(df_dat[df_dat['Name_modified'].str.contains('horten')].index, inplace=True)\n",
    "df_dat.drop(df_dat[df_dat['Name_modified'].str.contains('joukowsky')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Create dataframes with wings left to match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (2366, 5)\n",
      "Unmatched values left in big table : (1375, 5)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = initiate_df_left(df_bigtable, df_dat, df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Regex to match the family Yost,Eiffel,Eppler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Gottingen        381\n",
      "Eppler           196\n",
      "Uncategorized    138\n",
      "Wortmann         107\n",
      "NASA              54\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Family yost : correspondance if deleting the spaces points and / from big e\n",
    "- Family eiffel : correspondance if deleting the spaces and content between parenthesis + special case for eiffel 10 (wright) - 1903 wright flyer airfoil\t\n",
    "- Family eppler : correspondance if replacing eppler by e and removing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big table number of wings left beginning by e : (216, 6)\n",
      "Dat folder number of wings left beginning by e : (217, 6)\n",
      "Difference : -1\n"
     ]
    }
   ],
   "source": [
    "big_e, dat_e = get_letter_group(df_dat_left, df_big_left, 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "yost = [lambda x : (re.sub(\"\\s\", \"\", str(x))), \n",
    "        lambda x : (re.sub(\"\\.\", \"\", str(x))), \n",
    "        lambda x : (re.sub(\"/\", \"\", str(x)))]\n",
    "\n",
    "eiffel = [lambda x : (re.sub('\\(.*?\\)', \"\", str(x))), \n",
    "          lambda x : (re.sub(\"\\s\", \"\", str(x))), \n",
    "          lambda x : (re.split(\"-\", str(x)))[0]]\n",
    "\n",
    "eppler = [lambda x : (re.sub(\"eppler\", \"e\", str(x))),\n",
    "          lambda x : (re.sub(\"ee\", \"e\", str(x))),\n",
    "          lambda x : (re.sub(\"hydrofoil\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"strut\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"-\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"\\)\", \"\", str(x))),\n",
    "          lambda x : (re.sub(\"\\s\", \"\", str(x)))]\n",
    "\n",
    "big_e = try_pattern_family(big_e, 'Yost', yost)\n",
    "big_e = try_pattern_family(big_e, 'Eiffel', eiffel)\n",
    "big_e = try_pattern_family(big_e, 'Eppler', eppler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 1375 valeurs dont 208 correspondent aux fichiers dat.\n",
      "Il reste 1167 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "# Function to incorporate the new name found (Name_modified_by_family) into the dataset with the bigtable wings left to match\n",
    "df_big_left = incorporate_family_pattern(df_big_left, big_e)\n",
    "# Merge to match \n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Regex to match the family Gottingen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (2158, 6)\n",
      "Unmatched values left in big table : (1167, 6)\n",
      "Big table number of wings left beginning by g : (399, 6)\n",
      "Dat folder number of wings left beginning by g : (401, 6)\n",
      "Difference : -2\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')\n",
    "big_g, dat_g = get_letter_group(df_dat_left, df_big_left, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 1167 valeurs dont 372 correspondent aux fichiers dat.\n",
      "Il reste 795 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "gottingen = [lambda x : (re.sub(\"\\s\", \"\", str(x))), lambda x : (re.sub('\\(.*?\\)', \"\", str(x)))]\n",
    "big_g = try_pattern_family(big_g, 'Gottingen', gottingen)\n",
    "# Incorporating the new name found (Name_modified_by_family) into the dataset with the bigtable wings left to match\n",
    "df_big_left = incorporate_family_pattern(df_big_left, big_g)\n",
    "# Merge to match \n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Global regex with quick manual verif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1786, 6)\n",
      "Unmatched values left in big table : (795, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 795 valeurs dont 245 correspondent aux fichiers dat.\n",
      "Il reste 550 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))), \n",
    "                 lambda x : (re.sub(\"-\", \"\", str(x))), \n",
    "                 lambda x : (re.sub(\"%\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Uncategorized    100\n",
      "NASA              49\n",
      "Hepperle          49\n",
      "Selig et. al.     48\n",
      "Quabeck           42\n",
      "Leinauer          25\n",
      "Wortmann          22\n",
      "NACA/Munk         22\n",
      "Boeing            19\n",
      "Barth             16\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. keep trying**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1541, 6)\n",
      "Unmatched values left in big table : (550, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 550 valeurs dont 126 correspondent aux fichiers dat.\n",
      "Il reste 424 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\.\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\",\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"/\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"-\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"_\", \"\", str(x))),  \n",
    "                 lambda x : (re.sub(\"%\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\)\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Uncategorized    89\n",
      "Hepperle         49\n",
      "Selig et. al.    48\n",
      "Leinauer         25\n",
      "NACA/Munk        22\n",
      "NASA             20\n",
      "Boeing           19\n",
      "Wortmann         19\n",
      "Lockheed         14\n",
      "Gulfstream       14\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Smooth -> sm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1415, 6)\n",
      "Unmatched values left in big table : (424, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 424 valeurs dont 13 correspondent aux fichiers dat.\n",
      "Il reste 411 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\.\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\",\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"/\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"-\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"_\", \"\", str(x))),  \n",
    "                 lambda x : (re.sub(\"%\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\)\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"smoothed\", \"sm\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Removing whats between parenthesis with manual verif**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1402, 6)\n",
      "Unmatched values left in big table : (411, 6)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 411 valeurs dont 29 correspondent aux fichiers dat.\n",
      "Il reste 382 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "pattern_global =[lambda x : (re.sub('\\(.*?\\)', \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\s\", \"\", str(x)))]\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)\n",
    "\n",
    "df_big_left['parenthesis_content'] = df_big_left['Name_modified'].copy()\n",
    "df_big_left['parenthesis_content'] = df_big_left.loc[:, 'parenthesis_content'].apply(lambda x : (re.findall('\\(.*?\\)', str(x))))\n",
    "df_dat_left['parenthesis_content'] = df_dat_left['Name_modified'].copy()\n",
    "df_dat_left['parenthesis_content'] = df_dat_left.loc[:, 'parenthesis_content'].apply(lambda x : (re.findall('\\(.*?\\)', str(x))))\n",
    "\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family\n",
      "Uncategorized    70\n",
      "Hepperle         49\n",
      "Selig et. al.    28\n",
      "Leinauer         25\n",
      "NACA/Munk        22\n",
      "Name: nb_na, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "groupna_family(df_merge, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8. Family Hepperle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1373, 7)\n",
      "Unmatched values left in big table : (382, 7)\n",
      "Big table number of wings left beginning by m : (57, 7)\n",
      "Dat folder number of wings left beginning by m : (86, 7)\n",
      "Difference : -29\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')\n",
    "big_m, dat_m = get_letter_group(df_dat_left, df_big_left, 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "hepperle = [lambda x : (((re.split(\"\\s\", str(x)))[0])+(re.split(\"\\s\", str(x)))[1])]\n",
    "big_m = try_pattern_family(big_m, 'Hepperle', hepperle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 382 valeurs dont 49 correspondent aux fichiers dat.\n",
      "Il reste 333 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "df_big_left = incorporate_family_pattern(df_big_left, big_m)\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **9. Family NACA/Munk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (1324, 7)\n",
      "Unmatched values left in big table : (333, 7)\n",
      "Big table number of wings left beginning by n : (55, 7)\n",
      "Dat folder number of wings left beginning by n : (1023, 7)\n",
      "Difference : -968\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')\n",
    "big_n, dat_n = get_letter_group(df_dat_left, df_big_left, 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 333 valeurs dont 22 correspondent aux fichiers dat.\n",
      "Il reste 311 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "nacamunk = [lambda x : (re.sub(\"naca\",\"\", str(x))), lambda x : (re.sub(\"\\s\", \"\", str(x)))]\n",
    "big_n = try_pattern_family(big_n, 'NACA/Munk', nacamunk)\n",
    "df_big_left = incorporate_family_pattern(df_big_left, big_n)\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_family')\n",
    "df_dat_left.drop(df_dat_left[df_dat_left['Name_modified'].str.contains('naca')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **10. Family Gulfstream**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (323, 7)\n",
      "Unmatched values left in big table : (311, 7)\n"
     ]
    }
   ],
   "source": [
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 311 valeurs dont 14 correspondent aux fichiers dat.\n",
      "Il reste 297 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "# As much of giii rows in both dataset its the Gulfstream family \n",
    "giii_dat = df_dat_left[df_dat_left['Name_modified'].str.contains(\"giii\")]\n",
    "giii_big = df_big_left[df_big_left['Name_modified'].str.contains(\"giii\")]\n",
    "giinb = giii_big['Name_modified'].apply(lambda x : (re.findall('\\d+', str(x))))\n",
    "giinb = [int(nb[0]) for nb in giinb.values]\n",
    "giinb = sorted(giinb)\n",
    "giiiletter = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n']\n",
    "dict_giii = {}\n",
    "[dict_giii.update({('giiibl'+str(nb)) : ('giii'+str(letter))}) for nb, letter in zip(giinb, giiiletter)]\n",
    "df_big_left['Name_modified_by_pattern'] = df_big_left['Name_modified_by_pattern'].map(dict_giii).fillna(df_big_left['Name_modified_by_pattern'])\n",
    "\n",
    "df_merge = merge_df(df_big_left, df_dat_left, 'Name_modified_by_pattern')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (309, 7)\n",
      "Unmatched values left in big table : (297, 7)\n"
     ]
    }
   ],
   "source": [
    "# Get the unmatched names of each dataset\n",
    "df_dat_left, df_big_left = set_df_left(df_dat_left, df_merge, 'Name_modified_by_pattern')\n",
    "\n",
    "# Choose some regex to uniformize the names left\n",
    "pattern_global =[lambda x : (re.sub(\"\\s\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\.\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\",\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"/\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"-\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"_\", \"\", str(x))),  \n",
    "                 lambda x : (re.sub(\"%\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\(\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"\\)\", \"\", str(x))),\n",
    "                 lambda x : (re.sub(\"smoothed\", \"sm\", str(x)))]\n",
    "\n",
    "# Apply the pattern before trying to match by similarities\n",
    "df_dat_left, df_big_left = try_pattern(df_big_left, df_dat_left, pattern_global)\n",
    "\n",
    "# Download the dataframe left before the similarity affectation if needed\n",
    "# df_dat_left.to_csv('data/df_dat_left.csv')\n",
    "# df_big_left.to_csv('data/df_big_left.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 7)\n",
      "(297, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df_dat_left.shape)\n",
    "print(df_big_left.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of names to try matching\n",
    "list_big_modified = df_big_left['Name_modified'].values\n",
    "list_dat_modified = df_dat_left['Name_modified'].values\n",
    "\n",
    "list_big_modified_by_pattern = df_big_left['Name_modified_by_pattern'].values\n",
    "list_dat_modified_by_pattern = df_dat_left['Name_modified_by_pattern'].values\n",
    "\n",
    "list_big_modified_by_family = df_big_left['Name_modified_by_family'].values\n",
    "list_dat_modified_by_family = df_dat_left['Name_modified_by_family'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "def similar_fuzz(string1, string2):\n",
    "    return fuzz.partial_ratio(string1, string2)\n",
    "\n",
    "def find_match(list_big, list_dat):\n",
    "    ratio = []\n",
    "    word = []\n",
    "    match = []\n",
    "    partial_match = []\n",
    "    partial_ratio = []\n",
    "\n",
    "    for i in list_big:\n",
    "        maxscore = 0\n",
    "        maxpartial = 0\n",
    "        storeword = \"temp\"\n",
    "        storeword_partial = \"temp\"\n",
    "        for j in list_dat:\n",
    "            score = similar(i,j)\n",
    "            partial_score = similar_fuzz(i,j)\n",
    "            if (score > maxscore):\n",
    "                maxscore = score\n",
    "                storeword = j\n",
    "            # Equal score are not handled by this function\n",
    "            # It could be a great improvement \n",
    "            #if (score == maxscore):\n",
    "            if (partial_score > maxpartial):\n",
    "                maxpartial = partial_score\n",
    "                storeword_partial = j\n",
    "        word.append(i)\n",
    "        match.append(storeword)\n",
    "        ratio.append(maxscore)\n",
    "        partial_match.append(storeword_partial)\n",
    "        partial_ratio.append(maxpartial)\n",
    "        df_similar = pd.DataFrame(data={'Name' : word, 'Match' : match, 'Score' : ratio, 'Match_2' : partial_match, 'Score_2' : partial_ratio})\n",
    "    return df_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_verif_by_score(df, score):\n",
    "    max_born = score\n",
    "    min_born = score - 0.1\n",
    "    mask_score = (df['Score'] < max_born) & (df['Score'] >= min_born)\n",
    "    return df[mask_score].sort_values(by=['Score'], ascending=False)\n",
    "\n",
    "def manual_validation(df, score):\n",
    "    max_born = score\n",
    "    min_born = score - 0.1\n",
    "    mask_score = (df['Score'] < max_born) & (df['Score'] >= min_born)\n",
    "    df.loc[df[mask_score].index, 'checked'] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "0.9411764705882353\n",
      "0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "df_similar_modified = find_match(list_big_modified, list_dat_modified)\n",
    "df_similar_modified_by_pattern = find_match(list_big_modified_by_pattern, list_dat_modified_by_pattern)\n",
    "df_similar_modified_by_family = find_match(list_big_modified_by_family, list_dat_modified_by_family)\n",
    "print(df_similar_modified['Score'].max())\n",
    "print(df_similar_modified_by_pattern['Score'].max())\n",
    "print(df_similar_modified_by_family['Score'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with df_similar_modified_by_pattern since it contains the best score among the three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create some columns to store the result of basic verif\n",
    "df_similar_modified_by_pattern['checked'] = False\n",
    "df_similar_modified_by_pattern['same'] = False\n",
    "df_similar_modified_by_pattern['unique'] = False\n",
    "\n",
    "# We check if the match found are unique and if the 2 match found are the same\n",
    "mask_unique = df_similar_modified_by_pattern['Match'].value_counts() == 1\n",
    "index_unique = mask_unique[mask_unique == True].index.to_list()\n",
    "name_all = df_similar_modified_by_pattern['Match'].to_list()\n",
    "unique_col = []\n",
    "for name in name_all:\n",
    "    if(name in index_unique):\n",
    "        unique_col.append(True)\n",
    "    else:\n",
    "        unique_col.append(False)\n",
    "df_similar_modified_by_pattern['unique'] = unique_col\n",
    "df_similar_modified_by_pattern.loc[(df_similar_modified_by_pattern['Match'] == df_similar_modified_by_pattern['Match_2']), 'same'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result where the match is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Match</th>\n",
       "      <th>Score</th>\n",
       "      <th>Match_2</th>\n",
       "      <th>Score_2</th>\n",
       "      <th>checked</th>\n",
       "      <th>same</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ag44ct02f</td>\n",
       "      <td>ag44ct02r</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>ag44ct02r</td>\n",
       "      <td>89</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ag455ct02frot</td>\n",
       "      <td>ag455ct02r</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>ag455ct02r</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ag45c03f</td>\n",
       "      <td>ag45c03</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>ag45c03</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ag45ct02f</td>\n",
       "      <td>ag45ct02r</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>ag455ct02r</td>\n",
       "      <td>89</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ag46c03f</td>\n",
       "      <td>ag46c03</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>ag46c03</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name       Match     Score     Match_2  Score_2  checked   same  \\\n",
       "1      ag44ct02f   ag44ct02r  0.888889   ag44ct02r       89    False   True   \n",
       "2  ag455ct02frot  ag455ct02r  0.869565  ag455ct02r       90    False   True   \n",
       "3       ag45c03f     ag45c03  0.933333     ag45c03      100    False   True   \n",
       "4      ag45ct02f   ag45ct02r  0.888889  ag455ct02r       89    False  False   \n",
       "5       ag46c03f     ag46c03  0.933333     ag46c03      100    False   True   \n",
       "\n",
       "   unique  \n",
       "1    True  \n",
       "2    True  \n",
       "3    True  \n",
       "4    True  \n",
       "5    True  "
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_similar_modified_by_pattern[df_similar_modified_by_pattern['unique'] == True].copy()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 : (25, 8)\n",
      "0.9 : (49, 8)\n",
      "0.8 : (39, 8)\n",
      "0.7 : (29, 8)\n",
      "0.6 : (13, 8)\n",
      "0.5 : (11, 8)\n",
      "0.4 : (3, 8)\n",
      "0.3 : (2, 8)\n",
      "0.2 : (0, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f'{x/10} : {manual_verif_by_score(df, x/10).shape}') for x in range(10,1,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_verif_by_score(df, 1)\n",
    "df = manual_validation(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_verif_by_score(df, 0.9)\n",
    "df = manual_validation(df, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found 1 error with the correction below \n",
    "df.loc[df['Name'] == 'jwl0438821', 'Match'] =  'jwl043'\n",
    "manual_verif_by_score(df, 0.8)\n",
    "df = manual_validation(df, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found 1 error with the correction below \n",
    "df.loc[df['Name'] == 'ssv2316vansrv10', 'Match'] =  'ssv2316'\n",
    "manual_verif_by_score(df, 0.7)\n",
    "df = manual_validation(df, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found 4 error with the correction below \n",
    "df.loc[df['Name'] == 'uag92170sf', 'Match'] =  'uag92170sf'\n",
    "df.loc[df['Name'] == 'grummank2', 'Match'] =  'k2'\n",
    "df.loc[df['Name'] == 'grummank3', 'Match'] =  'k3'\n",
    "df.loc[df['Name'] == 'jh35', 'Match'] =  'jh35'\n",
    "\n",
    "manual_verif_by_score(df, 0.6)\n",
    "df = manual_validation(df, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_verif_by_score(df, 0.5)\n",
    "df = manual_validation(df, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found 1 error with the correction below \n",
    "df.loc[df['Name'] == 'lockheedc5abl4882', 'Match'] =  'c5b'\n",
    "\n",
    "manual_verif_by_score(df, 0.4)\n",
    "df = manual_validation(df, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found 1 error with the correction below \n",
    "df.loc[df['Name'] == 'flyingwingpeewee30', 'Match'] =  'flyingwingpeeWee30'\n",
    "\n",
    "manual_verif_by_score(df, 0.3)\n",
    "df = manual_validation(df, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Name'] == 'naca63215modb', 'checked'] =  True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result not unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 297 valeurs dont 175 correspondent aux fichiers dat.\n",
      "Il reste 122 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "# Merge the verified result \n",
    "df['Name_similar'] = df['Name'].copy()\n",
    "df_big_left['Name_similar'] = df_big_left['Name_modified_by_pattern'].copy()\n",
    "\n",
    "df_merge = pd.merge(df_big_left, df, on='Name_similar', how='left', suffixes=('_big', '_match'))\n",
    "nb_mismatch = df_merge[df_merge['Match'].isna()].shape[0]\n",
    "nb_match = df_merge.shape[0] - nb_mismatch\n",
    "print(f'Le dataset contient {df_merge.shape[0]} valeurs dont {nb_match} correspondent aux fichiers dat.')\n",
    "print(f'Il reste {nb_mismatch} valeurs à matcher.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (137, 8)\n",
      "Unmatched values left in big table : (122, 8)\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset with the unmatched values left\n",
    "# Merge the verified result \n",
    "df['Match_similar'] = df['Match'].copy()\n",
    "df_dat_left['Match_similar'] = df_dat_left['Name_modified_by_pattern'].copy()\n",
    "df_dat_left = pd.merge(df, df_dat_left, on='Match_similar', how='right', suffixes=('_match', '_dat'))\n",
    "df_dat_left = df_dat_left[df_dat_left['Match'].isna()]\n",
    "df_dat_left.dropna(axis=1, how='all', inplace=True)\n",
    "print(f\"Unmatched values left in the dat folder : {df_dat_left.shape}\")\n",
    "\n",
    "df_big_left = df_merge[df_merge['Match'].isna()].copy()\n",
    "df_big_left.dropna(axis=1, how='all', inplace=True)\n",
    "print(f\"Unmatched values left in big table : {df_big_left.shape}\")\n",
    "\n",
    "df_big_left = df_big_left[['Name_big', 'Family', 'Name_modified', 'Name_similar', 'parenthesis_content']]\n",
    "df_dat_left = df_dat_left[['Match_similar', 'Name_modified', 'Name_dat', 'parenthesis_content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relaunch similar on df left\n",
    "# Get list of names to try matching\n",
    "list_big_left = df_big_left['Name_similar'].values\n",
    "list_dat_left = df_dat_left['Match_similar'].values\n",
    "df_similar_left = find_match(list_big_left, list_dat_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 : (6, 5)\n",
      "0.9 : (11, 5)\n",
      "0.8 : (25, 5)\n",
      "0.7 : (15, 5)\n",
      "0.6 : (15, 5)\n",
      "0.5 : (29, 5)\n",
      "0.4 : (16, 5)\n",
      "0.3 : (5, 5)\n",
      "0.2 : (0, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f'{x/10} : {manual_verif_by_score(df_similar_left, x/10).shape}') for x in range(10,1,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_verif_by_score(df_similar_left, 1)\n",
    "df_similar_left = manual_validation(df_similar_left, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found 1 error with the correction below \n",
    "manual_verif_by_score(df_similar_left, 0.9)\n",
    "# match 2 is better than 1\n",
    "mask_score = (df_similar_left['Score'] < 0.8) & (df_similar_left['Score'] >= 0.9)\n",
    "df_similar_left.loc[df_similar_left[mask_score].index, 'Match'] = df_similar_left.loc[df_similar_left[mask_score].index, 'Match_2']\n",
    "df_similar_left = manual_validation(df_similar_left, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similar_left.loc[df_similar_left['checked'].isna(), 'Match'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found 1 error with the correction below \n",
    "df_similar_left.loc[df_similar_left['Name'] == 'hq17', 'Match'] = 'hq17'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'qa001sm', 'Match'] =  'qa001sm'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'qa002sm', 'Match'] =  'qa002sm'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 's301010384', 'Match'] =  's3010'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 's301409585', 'Match'] =  's3014'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 's301609587', 'Match'] =  's3016'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 's302109584', 'Match'] =  's3021'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'qa002', 'Match'] =  'qa002'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'jh817', 'Match'] =  'jh817'\n",
    "\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'du80176v1', 'Match'] = 'du80176v1'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'jh25', 'Match'] = 'jh25'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'qa001', 'Match'] =  'qa001'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'qa003', 'Match'] =  'qa003'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'du80141', 'Match'] =  'du80141'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'hawkertempest61semispan', 'Match'] =  'tempest2'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'hawkertempest375semispan', 'Match'] =  'tempest1'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'hawkertempest9677semispan', 'Match'] =  'tempest3'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'du80176v1alt', 'Match'] =  'du80176v1alt'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'lockheedc141bl0', 'Match'] =  'c141a'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 's1010hpvairfoil', 'Match'] =  's1010'\n",
    "\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'fage&collins1', 'Match'] = 'fg1'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'fage&collins2', 'Match'] = 'fg2'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'fage&collins3', 'Match'] = 'fg3'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'fage&collins4', 'Match'] = 'fg4'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'defiantcanardbl110', 'Match'] = 'defcnd2'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'defiantcanardbl145', 'Match'] = 'defcnd3'\n",
    "\n",
    "\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'marskepioneerianaca2311243012ahybrid', 'Match'] = 'marske2'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'marskepioneeriidrootnaca431012a24112hybrid', 'Match'] = 'marske3'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'marskepioneeriidtipnaca431012a', 'Match'] = 'marske4'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'marskepioneeriidtipnaca431012a*833hybrid', 'Match'] = 'marske4'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'marskemonarchnaca43012a', 'Match'] = 'marske5'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'lockheedgeorgiasupercritical', 'Match'] = 'lg10sc'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'be656865tc75cambersuitableforf1atowlinegliderc', 'Match'] = 'be6568'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'be669966maxtc99maxcamberclmax21atre100000trans', 'Match'] = 'be6699'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'sikorskysc1094r8', 'Match'] = 'sc1094r8'\n",
    "df_similar_left.loc[df_similar_left['Name'] == 'dragonflycanard', 'Match'] = 'drgnfly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 124 valeurs dont 53 correspondent aux fichiers dat.\n",
      "Il reste 71 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "# Merge the verified result \n",
    "df_similar_left['Name_similar'] = df_similar_left['Name'].copy()\n",
    "df_merge = pd.merge(df_big_left, df_similar_left, on='Name_similar', how='left', suffixes=('_big', '_match'))\n",
    "nb_mismatch = df_merge[df_merge['Match'].isna()].shape[0]\n",
    "nb_match = df_merge.shape[0] - nb_mismatch\n",
    "print(f'Le dataset contient {df_merge.shape[0]} valeurs dont {nb_match} correspondent aux fichiers dat.')\n",
    "print(f'Il reste {nb_mismatch} valeurs à matcher.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (102, 4)\n",
      "Unmatched values left in big table : (71, 9)\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset with the unmatched values left\n",
    "# Merge the verified result \n",
    "df_similar_left['Match_similar'] = df_similar_left['Match'].copy()\n",
    "df_dat_left = pd.merge(df_similar_left, df_dat_left, on='Match_similar', how='right', suffixes=('_match', '_dat'))\n",
    "df_dat_left = df_dat_left[df_dat_left['Match'].isna()]\n",
    "df_dat_left.dropna(axis=1, how='all', inplace=True)\n",
    "print(f\"Unmatched values left in the dat folder : {df_dat_left.shape}\")\n",
    "\n",
    "df_big_left = df_merge[df_merge['Match'].isna()].copy()\n",
    "df_big_left.dropna(axis=1, how='all', inplace=True)\n",
    "print(f\"Unmatched values left in big table : {df_big_left.shape}\")\n",
    "\n",
    "df_big_left = df_big_left[['Name_big', 'Family', 'Name_modified', 'Name_similar', 'parenthesis_content']]\n",
    "df_dat_left = df_dat_left[['Match_similar', 'Name_modified', 'Name_dat', 'parenthesis_content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of names to try matching\n",
    "list_big_left = df_big_left['Name_similar'].values\n",
    "list_dat_left = df_dat_left['Match_similar'].values\n",
    "\n",
    "df_similar_left2 = find_match(list_big_left, list_dat_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  (0, 5)\n",
      "0.9 :  (0, 5)\n",
      "0.8 :  (24, 5)\n",
      "0.7 :  (4, 5)\n",
      "0.6 :  (4, 5)\n",
      "0.5 :  (20, 5)\n",
      "0.4 :  (16, 5)\n",
      "0.3 :  (3, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"1 : \", manual_verif_by_score(df_similar_left2, 1).shape)\n",
    "print(\"0.9 : \",manual_verif_by_score(df_similar_left2, 0.9).shape)\n",
    "print(\"0.8 : \",manual_verif_by_score(df_similar_left2, 0.8).shape)\n",
    "print(\"0.7 : \",manual_verif_by_score(df_similar_left2, 0.7).shape)\n",
    "print(\"0.6 : \",manual_verif_by_score(df_similar_left2, 0.6).shape)\n",
    "print(\"0.5 : \",manual_verif_by_score(df_similar_left2, 0.5).shape)\n",
    "print(\"0.4 : \",manual_verif_by_score(df_similar_left2, 0.4).shape)\n",
    "print(\"0.3 : \",manual_verif_by_score(df_similar_left2, 0.3).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7)\n",
      "(62, 7)\n"
     ]
    }
   ],
   "source": [
    "df_similar_left2['unique'] = False\n",
    "df_similar_left2['check'] = False\n",
    "mask_unique = df_similar_left2['Match'].value_counts() == 1\n",
    "index_unique = mask_unique[mask_unique == True].index.to_list()\n",
    "name_all = df_similar_left2['Match'].to_list()\n",
    "unique_col = []\n",
    "for name in name_all:\n",
    "    if(name in index_unique):\n",
    "        unique_col.append(True)\n",
    "    else:\n",
    "        unique_col.append(False)\n",
    "df_similar_left2['unique'] = unique_col\n",
    "df_similar_left2.drop(index=[14,19,30,44], axis=0, inplace=True)\n",
    "df_unique = df_similar_left2[df_similar_left2['unique'] == True]\n",
    "df_duplicates = df_similar_left2[df_similar_left2['unique'] == False]\n",
    "print(df_unique.shape)\n",
    "print(df_duplicates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similar_left2.loc[df_similar_left2['unique'] == True, 'check'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates.sort_values(by=['Score'], ascending=False, ignore_index=True)\n",
    "df_duplicates.loc[:, 'Match'] = df_duplicates.loc[:, 'Match_2'] \n",
    "df_duplicates.loc[df_duplicates['Name'] == 'davisbasicb24wing', 'Match'] = 'davis_corrected'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'lockheedc141bl1136', 'Match'] = 'c141b'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'lockheedc141bl42657', 'Match'] = 'c141c'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'lockheedc141bl61061', 'Match'] = 'c141d'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'lockheedc141bl76111', 'Match'] = 'c141e'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'lockheedc141bl95889', 'Match'] = 'c141f'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'lockheedc5abl1256', 'Match'] = 'c5e'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'lockheedc5abl576', 'Match'] = 'c5c'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'lockheedc5abl7586', 'Match'] = 'c5d'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'marskexm1df1430', 'Match'] = 'marske1'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'naca001034a=08cli=02', 'Match'] = 'naca001034a08cli0'\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'ronczlowdragflyingwing', 'Match'] = 'marske7'\n",
    "\n",
    "df_duplicates.loc[:, 'check'] = True\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'deesokay230', 'check'] = False\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'naca001264a=08cli=02', 'check'] = False\n",
    "df_duplicates.loc[df_duplicates['Name'] == 'x35lowdragbody', 'check'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_duplicates, df_unique], ignore_index=True,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyrano II P-30 cyranoiip30\n",
    "# jhsym10 JHSYM-10\n",
    "# naca6621812a=6p51tip\t not found\n",
    "# swallowp30 SwallowP-30\n",
    "#deesokay230 surement problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le dataset contient 71 valeurs dont 67 correspondent aux fichiers dat.\n",
      "Il reste 4 valeurs à matcher.\n"
     ]
    }
   ],
   "source": [
    "# Merge the verified result \n",
    "df_final['Name_similar'] = df_final['Name'].copy()\n",
    "df_merge = pd.merge(df_big_left, df_final, on='Name_similar', how='left', suffixes=('_big', '_match'))\n",
    "nb_mismatch = df_merge[df_merge['Match'].isna()].shape[0]\n",
    "nb_match = df_merge.shape[0] - nb_mismatch\n",
    "print(f'Le dataset contient {df_merge.shape[0]} valeurs dont {nb_match} correspondent aux fichiers dat.')\n",
    "print(f'Il reste {nb_mismatch} valeurs à matcher.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched values left in the dat folder : (46, 4)\n",
      "Unmatched values left in big table : (4, 5)\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset with the unmatched values left\n",
    "# Merge the verified result \n",
    "df_final['Match_similar'] = df_final['Match'].copy()\n",
    "df_dat_left = pd.merge(df_final, df_dat_left, on='Match_similar', how='right', suffixes=('_match', '_dat'))\n",
    "df_dat_left = df_dat_left[df_dat_left['Match'].isna()]\n",
    "df_dat_left.dropna(axis=1, how='all', inplace=True)\n",
    "print(f\"Unmatched values left in the dat folder : {df_dat_left.shape}\")\n",
    "\n",
    "df_big_left = df_merge[df_merge['Match'].isna()].copy()\n",
    "df_big_left.dropna(axis=1, how='all', inplace=True)\n",
    "print(f\"Unmatched values left in big table : {df_big_left.shape}\")\n",
    "\n",
    "df_big_left = df_big_left[['Name_big', 'Family', 'Name_modified', 'Name_similar', 'parenthesis_content']]\n",
    "df_dat_left = df_dat_left[['Match_similar', 'Name_modified', 'Name_dat', 'parenthesis_content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_big</th>\n",
       "      <th>Family</th>\n",
       "      <th>Name_modified</th>\n",
       "      <th>Name_similar</th>\n",
       "      <th>parenthesis_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BOEING-VERTOL VR-9</td>\n",
       "      <td>Boeing</td>\n",
       "      <td>boeing-vertol vr-9</td>\n",
       "      <td>boeingvertolvr9</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HUGHES HELICOPTERS HH-02</td>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>hughes helicopters hh-02</td>\n",
       "      <td>hugheshelicoptershh02</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>JWL068 9.5/1.7</td>\n",
       "      <td>Leinauer</td>\n",
       "      <td>jwl068 9.5/1.7</td>\n",
       "      <td>jwl0689517</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NACA 5-H-10</td>\n",
       "      <td>NACA</td>\n",
       "      <td>naca 5-h-10</td>\n",
       "      <td>naca5h10</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name_big         Family             Name_modified  \\\n",
       "14        BOEING-VERTOL VR-9         Boeing        boeing-vertol vr-9   \n",
       "19  HUGHES HELICOPTERS HH-02  Uncategorized  hughes helicopters hh-02   \n",
       "30            JWL068 9.5/1.7       Leinauer            jwl068 9.5/1.7   \n",
       "44               NACA 5-H-10           NACA               naca 5-h-10   \n",
       "\n",
       "             Name_similar parenthesis_content  \n",
       "14        boeingvertolvr9                  []  \n",
       "19  hugheshelicoptershh02                  []  \n",
       "30             jwl0689517                  []  \n",
       "44               naca5h10                  []  "
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_left"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
